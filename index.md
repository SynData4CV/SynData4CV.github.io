---
layout: default
---
<style> 
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 75%;
} </style>

# Overview
<div style="text-align: justify">
The overarching goal of this workshop is to gather researchers, students, and advocates who work at the intersection of accessibility, computer vision, and autonomous systems. We plan to use the workshop to identify challenges and pursue solutions for the current lack of shared and principled development tools for data-driven vision-based accessibility systems. For instance, there is a general lack of vision-based benchmarks and methods relevant to accessibility (e.g., people with disabilities and mobility aids are currently mostly absent from large-scale datasets in pedestrian detection). Our workshop will provide a unique opportunity for fostering a mutual discussion between accessibility, computer vision, and robotics researchers and practitioners.
</div>

# Invited Speakers
<div style="display: flex">
  
  <div style="width:22.5%">
    <a href="https://www.inclusivemobility.com/">
    <img alt="Chandrika Jayant" src="pics/chandrika_jayant.jfif"  height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://www.inclusivemobility.com/">Chandrika Jayant</a><br>
    Volkswagen Group of America, Principal Designer and Manager, Inclusive Mobility Team
  </div>
  
  <div style="width:2.5%">
  </div>

  <div style="width:22.5%">
    <a href="http://www.cs.cmu.edu/~deva/">
    <img alt="speaker2" src="pics/Ramanan.png" height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
    <a href="http://www.cs.cmu.edu/~deva/">Deva Ramanan</a><br>
    Carnegie Mellon University and Argo AI 
  </div>
  
  <div style="width:2.5%">
  </div>

  <div style="width:22.5%">
    <a href="https://jonfroehlich.github.io/">
    <img alt="Jon E. Froehlich" src="pics/jon_e_froehlich.jpg"   height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://jonfroehlich.github.io/">Jon E. Froehlich</a><br>
    University of Washington, Researcher in Human-Computer Interaction and Accessibility
  </div>
  
  <div style="width:2.5%">
  </div>
  <div style="width:22.5%">
    <a href="https://www.ski.org/users/james-coughlan">
    <img alt="speaker4" src="pics/james_coughlan.jpg" height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
    <a href="https://www.ski.org/users/james-coughlan">James Coughlan </a><br>
    Smith-Kettlewell Eye Research Institute, Researcher in Computer Vision Technologies for Blind and Visually Impaired
  </div>
</div>
  
<div style="display: flex">
  <div style="width:2.5%">
  </div>
    <div style="width:22.5%">
    <a href="https://adriengaidon.com/">
    <img alt="speaker5" src="pics/adrien_gaidon.png" height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
    <a href="https://adriengaidon.com/">Adrien Gaidon </a><br>
    Toyota Research Institute, Head of Machine Learning Research
  </div>
  
  <div style="width:2.5%">
  </div>
  <div style="width:22.5%">
    <a href="https://pelilab.partners.org/">
    <img alt="speaker6" src="pics/eli_peli.jpg" height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
    <a href="https://pelilab.partners.org/"> Eli Peli </a><br>
    Harvard, Professor of Ophthalmology Harvard Medical School, Researcher in Disability, Rehabilitation, and Assistive Technologies for Low Vision
  </div>
  
  <div style="width:2.5%">
  </div>
  <div style="width:22.5%">
    <a href="https://https://giarre.wordpress.com/">
    <img alt="speaker7" src="pics/laura_giarré.png" height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
    <a href="https://giarre.wordpress.com/"> Laura Giarré </a><br>
    University of Modena and Reggio Emilia, NTNU 
  </div>
</div>


## Schedule

| Time | Event | Duration |
| ----- | ----- | ----- |
| 08:30-08:35 | introduction/opening remarks | (5 min)

| Time | Event | 
| ----- | ----- |
| 08:30-08:35 | introduction/opening remarks | 

| Time (CDT) | Talk |
| ----- | ----- | 
| 13:00 | Opening Remarks
| 13:05-13:30 | Deva Ramanan (In-Person)
| 13:35-14:00 | Chandrika Jayant, ``Inclusive Mobility at Volkswagen Group of America’’
| 14:05-14:30 | Jon E. Froehlich / Michael Saugstad (University of Washington), ``Project Sidewalk: Crowd+AI Tools to Map and Assess Sidewalk Accessibility’’
| 14:35-15:00 | Adrien Gaidon, ``Principle-centric AI’’  (In-Person)
| 15:00-15:15 | Challenge Results, 1-Minute Poster Highlights
| 15:15-15:35 | Poster Session #1 + Break
| 15:35-15:55 | Laura Giarré, ``Accessibility and Independent Navigation for People with Visual Impairments'’
| 16:00-16:25 | Eli Peli, ``Pedestrian Collision with Homonymous Hemianopia’’
| 16:30-16:55 | James Coughlan
| 16:55-17:20 | Concluding Remarks + Poster Session #2

## Organizers
<div style="display: flex">
  <div style="width:22.5%">
    <a href="https://eshed1.github.io/">
    <img alt="Eshed Ohn-Bar" src="pics/eshed_ohn_bar.jpg" height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
    <a href="https://eshed1.github.io/">Eshed Ohn-Bar</a><br>
    Boston University
  </div>
  
  <div style="width:2.5%">
  </div>
   
  <div style="width:22.5%">
    <a href="https://home.cs.colorado.edu/~DrG/AboutMe.html">
    <img alt="Danna Gurari" src="pics/danna_gurari.jpg"  height="200"   width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://home.cs.colorado.edu/~DrG/AboutMe.html">Danna Gurari</a><br>
    University of Colorado Boulder
  </div>
  
  <div style="width:2.5%">
  </div>
   
  <div style="width:22.5%">
    <a href="http://www.cs.cmu.edu/~kkitani/">
    <img alt="Kris Kitani" src="pics/kitani_kris.jpg"  height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="http://www.cs.cmu.edu/~kkitani/">Kris Kitani</a><br>
    Carnegie Mellon University
  </div>
  
  <div style="width:2.5%">
  </div>
   
  <div style="width:22.5%">
    <a href="http://ai.bu.edu/ksaenko.html#">
    <img alt="Kate Saenko" src="pics/kate_saenko.png"   height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="http://ai.bu.edu/ksaenko.html#">Kate Saenko</a><br>
   Boston University
  </div>
</div>

<div style="display: flex">
  <div style="width:22.5%">
    <a href="http://www.cvlibs.net/">
    <img alt="Andreas Geiger" src="pics/andreas_geiger.jpg"   height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
    <a href="http://www.cvlibs.net/">Andreas Geiger</a><br>
    University of Tübingen and the MPI for Intelligent Systems
  </div>
  
  <div style="width:2.5%">
  </div>
  
  <div style="width:22.5%">
    <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-chiekoa">
    <img alt="Chieko Asakawa" src="pics/chieko_asakawa.jpg"   height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-chiekoa">Chieko Asakawa</a><br>
    Carnegie Mellon University and IBM
  </div>

  <div style="width:2.5%">
  </div>
  
  <div style="width:22.5%">
    <a href="https://jonfroehlich.github.io/">
    <img alt="Jon E. Froehlich" src="pics/jon_e_froehlich.jpg"   height="200" width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://jonfroehlich.github.io/">Jon E. Froehlich</a><br>
    University of Washington
  </div>
  
  <div style="width:2.5%">
  </div>
  
  <div style="width:22.5%">
    <a href="https://www.inclusivemobility.com/">
    <img alt="Chandrika Jayant" src="pics/chandrika_jayant.jfif"  height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://www.inclusivemobility.com/">Chandrika Jayant</a><br>
    Volkswagen Group of America
  </div>
</div>


<!-- ## Advising committee -->

<!-- <div style="display: flex">
 <div style="width:22.5%">
    <a href="https://staging-temp-site.github.io/staging-temp-site.gitub.io/">
    <img alt="name_16" src="pics/placeholder.jpg"  height="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://staging-temp-site.github.io/staging-temp-site.gitub.io/">[Name]</a><br>
    [Institution]
  </div>
  
  <div style="width:2.5%">
  </div>
   
  <div style="width:22.5%">
    <a href="https://staging-temp-site.github.io/staging-temp-site.gitub.io/">
    <img alt="name_16" src="pics/placeholder.jpg"  height="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="https://staging-temp-site.github.io/staging-temp-site.gitub.io/">[Name]</a><br>
    [Institution]
  </div>
</div> -->



<!-- ## Program Committee -->
<!-- 
| --- | --- |
|  |  | -->

<!-- ## Student Organizers -->
<!-- 
| --- | --- |
|  |  |
 -->


<!-- ## Call for papers -->
<!-- Please refer to the **[call for papers](./call-for-papers.html)** page for more details. -->

<!-- 
<div style="text-align: center">
<u><g8>Challenge</g8></u>
</div>
 -->

<!-- ## Challenge overview -->
<!-- 
<div style="text-align: justify">


Towards building a community of accessibility research in computer vision conferences, we introduce a computer vision challenge with synthetic and real-world benchmarks. The challenge (based on our ICCV’21 paper, <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_X-World_Accessibility_Vision_and_Autonomy_Meet_ICCV_2021_paper.pdf">bit.ly/2X8sYoX</a>) will be used to benchmark various computer vision tasks when comparing new and established methods for fine-grained perception of tasks relevant to people with disabilities. The challenge is designed in the spirit of various other vision challenges that help advance the state-of-the-art of computer vision for autonomous systems, e.g., in robust vision (CVPR’21), human action recognition trajectory forecasting (CVPR’21), etc. E
 </div>
<div class = "center">
    <img alt="fig1" src="pics/fig1.svg" >
    <p>Fig. 1: An interactive simulation environment will be used as part of the workshop challenge for training machine perception and learning models in the context of accessibility (taken from <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_X-World_Accessibility_Vision_and_Autonomy_Meet_ICCV_2021_paper.pdf">bit.ly/2X8sYoX</a>).</p>
<br> 
<div class = "center">
    <img alt="fig2" src="pics/fig2.svg" >
    <p>An example from the instance segmentation challenge for perceiving people with mobility aids.</p>
</div>
<br> 
</div>
<br>-->


## Challenge Organization

<div style="display: flex">
  <div style="width:22.5%">
    <a href="mailto:zhangjim@bu.edu">
    <img alt="Jimuyang Zhang" src="pics/jimuyang_zhang.jpg"  style =  "border-radius: 50%; object-fit: cover; width = 100% ">
    </a><br>
    <a href="mailto:zhangjim@bu.edu">Jimuyang Zhang</a><br>
    Boston University
  </div>
  
  <div style="width:2.5%">
  </div>
   
  <div style="width:22.5%">
    <a href="mailto:sgzk@bu.edu">
    <img alt="Zhongkai Shangguan" src="pics/zhongkai_shangguan.png"   style =  "border-radius: 50%; object-fit: cover; width = 100% ">
    </a><br>
  <a href="mailto:sgzk@bu.edu">Zhongkai Shangguan</a><br>
    Boston University
  </div>
  
  <div style="width:2.5%">
  </div>
   
  <div style="width:22.5%">
    <a href="mailto:mzheng27@bu.edu">
    <img alt="Minglan Zheng" src="pics/minglan_zheng.png"   style =  "border-radius: 50%; object-fit: cover; width = 100% ">
    </a><br>
  <a href="mailto:mzheng27@bu.edu">Minglan Zheng</a><br>
    Boston University
  </div>
  
  <div style="width:2.5%">
  </div>
<!--    
  <div style="width:22.5%">
    <a href="http://ai.bu.edu/ksaenko.html#">
    <img alt="Kate Saenko" src="pics/kate_saenko.png"   height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
    </a><br>
  <a href="http://ai.bu.edu/ksaenko.html#">Kate Saenko</a><br>
   Boston University
  </div> -->
</div>


## Challenge

<div style="text-align: justify">
The challenge involves a synthetic instance segmentation benchmark incorporating use-cases of autonomous systems interacting with pedestrians with disabilities (see Zhang et al., X-World: Accessibility, Vision, and Autonomy Meet, ICCV 2021 <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_X-World_Accessibility_Vision_and_Autonomy_Meet_ICCV_2021_paper.pdf">bit.ly/2X8sYoX</a>). The benchmark contains challenging accessibility-related person and object categories, such as `cane' and `wheelchair.' We aim to use the challenge to uncover research opportunities and spark the interest of computer vision and AI researchers working on more robust visual reasoning models for accessibility. 
  
<div class = "center">
    <img alt="fig2" src="pics/i1.jpg" >
    <p>An example from the instance segmentation challenge for perceiving people with mobility aids.</p>
</div>
  <br>
  The team with the top performing submission will be invited to give short talks during the workshop and will receive a financial award of <b>$500</b> and an <a href="https://store.opencv.ai/products/oak-d">OAK—D camera</a>. 
  <br><br>
  
  To participate in the challenge and download the data please go to the <a href="https://eval.ai/web/challenges/challenge-page/1690/overview">challenge website.</a>
  
  
</div>

## Call for Papers

<div style="text-align: justify">
We encourage submission of relevant research (including work in progress, novel perspectives, formative studies, benchmarks, methods) as extended abstracts for the poster session and workshop discussion (up to 4 pages in CVPR format, not including references). CVPR Overleaf template can be <a href="https://www.overleaf.com/latex/templates/cvpr-2022-author-kit/qbmjsdxryffn">found here</a>. Latex/Word templates can be <a href="https://cvpr2022.thecvf.com/sites/default/files/2021-10/cvpr2022-author_kit-v1_1-1.zip">found here</a>. Please send your extended abstracts to <a href="mailto:mobility@bu.edu">mobility@bu.edu</a>. Note that submissions do not need to be anonymized. Extended abstracts of already published works can also be submitted. Accepted abstracts will be presented at the poster session, and will not be included in the printed proceedings of the workshop.
Topics of interests by this workshop include, but are not limited to:
  <br>
  <ol>
  <li>AI for Accessibility</li>
  <li>Accessibility-Centered Computer Vision Tasks and Datasets</li>
  <li>Data-Driven Accessibility Tools, Metrics and Evaluation Frameworks</li>
  <li>Practical Challenges in Ability-Based Assistive Technologies</li>  
  <li>Accessibility in Robotics and Autonomous Vehicles</li>  
  <li>Long-Tail and Low-Shot Recognition of Accessibility-Based Tasks</li>  
  <li>Accessible Homes, Hospitals, Cities, Infrastructure, Transportation</li>   
  <li>Crowdsourcing and Annotation Tools for Vision and Accessibility</li>  
  <li>Empirical Real-World Studies in Inclusive System Design</li>  
  <li>Assistive Human-Robot Interaction</li>  
  <li>Remote Accessibility Systems</li>   
  <li>Multi-Modal (Audio, Visual, Inertial, Haptic) Learning and Interaction</li>  
  <li>Accessible Mobile and Information Technologies</li>  
  <li>Virtual, Augmented, and Mixed Reality for Accessibility</li>  
  <li>Novel Designs for Robotic, Wearable and Smartphone-Based Assistance</li>  
  <li>Intelligent Assistive Embodied and Navigational Agents</li>   
  <li>Socially Assistive Mobile Applications</li>  
  <li>Human-in-the-Loop Machine Learning Techniques</li>  
  <li>Accessible Tutoring and Education</li>  
  <li>Personalization for Diverse Physical, Motor, and Cognitive Abilities</li>  
  <li>Embedded Hardware-Optimized Assistive Systems</li>  
  <li>Intelligent Robotic Wheelchairs</li>  
  <li>Medical and Social and Cultural Models of Disability</li>  
  <li>New Frameworks for Taxonomies and Terminology</li>  
    </ol>
</div>

## Important workshop dates
- Challenge release: <strong>February 27, 2022.</strong>
- Workshop abstract submission deadline: <strong>June 11, 2022.</strong> (11:59PM EST, please submit extended abstracts via email to mobility@bu.edu)
- Challenge submission deadline: <strong>June 10, 2022.</strong> (11:59PM EST)
- Abstract notification: <strong>June 13, 2022.</strong>
- Challenge winner announcement: <strong>June 20, 2022.</strong>


<!-- ### Join our **[mailing list](https://staging-temp-site.github.io/staging-temp-site.gitub.io/)** for updates. -->

<!-- ## Videos -->

<!-- <div style=" float: center;">
    <div align="center" style="width:45%; float: left;">
      <h4><u>OpenGuide</u> </h4>
        <iframe src="https://www.youtube.com/embed/mGq9sL1spzc" frameborder="0"
          allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
          style="width:100%; clip-path:inset(1px 1px);height: 30vh" allowfullscreen></iframe>
    </div>
    <div style="width:5%; float: left;">
        <p></p>
    </div>
    
    <!--div align="center"  style="width:45%; float: left;">
      <h4 ><u>X-World</u> </h4>
      
        <iframe src="https://www.youtube.com/embed/z_YwWIZWg58" frameborder="0"
          allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
          style="width:100%; clip-path:inset(1px 1px); height: 30vh" allowfullscreen></iframe>
      
    </div>
  </div--> 

